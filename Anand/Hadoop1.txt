01/09/2018

What is Hadoop?

1. HADOOP is a open source tool which handle the BIG DATA.
2. IT is the base of big data applications.
3. It is written in java programming language.
4. It works on mster slave architecture.
5. It is framewok based.
6. It stores data in HDFS(Hadoop distributed files system).
7. It is based on batch files processing.
8. Stores and process all type of data.


HDFS: Hadoop distributed file system, it is file system used for storage of large amount of data as in normal pc we have NTFS type(windows), for storage of small amount of data. HDFS is a open source cluster framework.

Open-Source : Open-source means we can contribute in changing. We can see its code, and can modify.
Cluster : It is a group of computers.

Our normal system is consist of (MBR+BIOS) which don't support a harddisk of more than 2TB. If we want to increase its capibity then we have to use (GPT + UEFI) combination.

Version of Hadoop:
	HADOOP 1.0
	Whenever there is a small change in software then version changes are as (version 1.0.0 to version 1.0.1) and when there is very big 		change in software then then version change is as (version 1.0.0 to version 2.0.0).
	HADOOP run 5 daemons NN,SNN,DN,TT,JT. 
	Daemons: Daemons are the programs which run behind the system. *They are programs not system. BAsically they are just java programs.
HADOOP ARCHITECTURE:
	HADOOP architecture is based on MASTER-SLAVE architecture where there is only one MASTER but many SLAVES. In this system MASTER need 		to be powerful i.e it should consist of powerful processor, RAM, Storage etc where as SLAVES can be a normal computer.
	Out of 5 daemons NN,SNN, and JT are called MASTER node and comes in HDFS whereas DN, TT are called SLAVE nodes and comes under 		MapReduce. 

Working:

NAME NODE(NN): It stores META data i.e data about data. In simple language if consider us as data then people who know adress of ours they are 			META data. Name node stores all the info about how and where the data is stores in data nodes. It consist of two files editlog 			and fsImage.
		EditLog file : It has record of every change you have made since NAME Node is created.
		FsImage : ?? 
DATA NODE(DN): It actually stores real data. It sends heart-beats( signals) after every 3sec to JT.

Job Tracor(JT): 1) Scheduling.
		2) Monitoring.
		3) Resource Allocation.

SECONDARY NODE(SNN): 	It is sort of backup but can't be named as backup bacause it can't take over automatically if NAME NODE crashes. Admin 				have to set it as NAME node. It takes Editlog file and FsImage files combines and creates an Updated FsImage file then 				transfer it ot Name Node.

PROBLEMS WITH HADOOP !.0
1. No automatic take over.
2. We can not make nodes more than 4000.
3. No real time processing.
4. Latency.
5. It has Job tracker to perform many activities.
6. It has the static map and reduce configuration.

Thank you for reading.
Question.1 : How does FsImage files stores data? 

